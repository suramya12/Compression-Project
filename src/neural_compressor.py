"""
Neural Image Compression Module

Uses CompressAI's pre-trained models to achieve state-of-the-art compression
that outperforms AVIF while maintaining high quality.

Supports NCI2 (legacy) and NCI3 (overlapped tiling, adaptive quality, ONNX) formats.
"""

import os
from pathlib import Path
from typing import Tuple, Optional, Union, List, Dict
from dataclasses import dataclass
import numpy as np
from PIL import Image
import torch
import io
import struct
import math


@dataclass
class NeuralCompressionResult:
    """Result of neural compression operation."""
    success: bool
    output_path: Optional[Path]
    original_size: int
    compressed_size: int
    compression_ratio: float
    quality_level: int
    message: str


class NeuralCompressor:
    """
    Neural image compression using CompressAI.

    Achieves higher compression than AVIF while maintaining quality.
    Uses pre-trained autoencoder with hyperprior entropy model.
    Supports tiling for efficient processing of large resolution images.

    NCI3 format features:
    - Overlapped tiling with linear gradient blending (eliminates seam artifacts)
    - Adaptive per-tile quality based on content complexity
    - Optional ONNX inference for lightweight deployment
    """

    MODEL_ID_MAP = {
        "mbt2018_mean": 1,
        "cheng2020_anchor": 2,
        "elic": 3,
    }
    MODEL_NAME_MAP = {v: k for k, v in MODEL_ID_MAP.items()}

    def __init__(
        self,
        quality: int = 6,
        model_name: str = "elic",
        tile_size: int = 1024,
        overlap: int = 64,
        quality_mode: str = "fixed",
        verbose: bool = True,
        use_onnx: bool = False,
        onnx_model_dir: Optional[str] = None
    ):
        """
        Initialize neural compressor.

        Args:
            quality: Quality level (1-9 for elic, 1-8 for mbt2018, 1-6 for cheng2020)
            model_name: Model architecture ("elic", "mbt2018_mean", or "cheng2020_anchor")
            tile_size: Size of tiles for processing large images (default 1024)
            overlap: Pixel overlap between tiles (default 64, 0 = no overlap)
            quality_mode: "fixed" for uniform quality, "adaptive" for per-tile quality
            verbose: Print progress
            use_onnx: Use ONNX runtime for inference if available
            onnx_model_dir: Directory containing exported ONNX models
        """
        self.quality = quality
        self.model_name = model_name
        self.tile_size = tile_size
        self.overlap = overlap
        self.quality_mode = quality_mode
        self.verbose = verbose
        self.use_onnx = use_onnx
        self.onnx_model_dir = onnx_model_dir
        self._model_cache: Dict[Tuple[str, int], object] = {}
        self._device = None
        self._onnx_engine = None

    def _log(self, msg: str):
        if self.verbose:
            print(msg)

    def _get_device(self):
        """Get the compute device."""
        if self._device is None:
            self._device = 'cuda' if torch.cuda.is_available() else 'cpu'
        return self._device

    def _get_model(self, model_name: Optional[str] = None, quality: Optional[int] = None):
        """Lazy load a model, with caching by (model_name, quality)."""
        model_name = model_name or self.model_name
        quality = quality or self.quality
        cache_key = (model_name, quality)

        if cache_key not in self._model_cache:
            device = self._get_device()
            self._log(f"Loading {model_name} quality {quality} on {device}...")

            if model_name == "elic":
                from compressai.zoo import elic2022_chandelier
                model = elic2022_chandelier(quality=quality, pretrained=True)
                model.update()  # Update entropy model CDFs
            elif model_name == "mbt2018_mean":
                from compressai.zoo import mbt2018_mean
                model = mbt2018_mean(quality=quality, pretrained=True)
            elif model_name == "cheng2020_anchor":
                from compressai.zoo import cheng2020_anchor
                model = cheng2020_anchor(quality=quality, pretrained=True)
            else:
                raise ValueError(f"Unknown model: {model_name}")

            self._model_cache[cache_key] = model.eval().to(device)
            self._log("Model loaded!")

        return self._model_cache[cache_key], self._get_device()

    def _get_onnx_engine(self):
        """Get or create the ONNX inference engine."""
        if self._onnx_engine is None and self.use_onnx and self.onnx_model_dir:
            try:
                from .onnx_export import ONNXInferenceEngine
                self._onnx_engine = ONNXInferenceEngine(self.onnx_model_dir)
                self._log("ONNX inference engine loaded!")
            except Exception as e:
                self._log(f"ONNX engine not available, falling back to PyTorch: {e}")
                self.use_onnx = False
        return self._onnx_engine

    def _pad_image(self, img: Image.Image, factor: int = 64) -> Image.Image:
        """Pad image to be divisible by factor using reflect padding."""
        w, h = img.size
        pad_w = (factor - w % factor) % factor
        pad_h = (factor - h % factor) % factor

        if pad_w > 0 or pad_h > 0:
            img_np = np.array(img)
            # Reflect padding for better border quality
            padded_np = np.pad(
                img_np,
                ((0, pad_h), (0, pad_w), (0, 0)),
                mode='reflect'
            )
            return Image.fromarray(padded_np)
        return img

    def _calculate_tile_complexity(self, tile: Image.Image) -> float:
        """
        Calculate tile complexity based on variance of 16x16 blocks.

        Returns a normalized complexity score in [0, 1].
        """
        gray = np.array(tile.convert('L'), dtype=np.float32)
        h, w = gray.shape

        block_size = 16
        variances = []

        for y in range(0, h - block_size + 1, block_size):
            for x in range(0, w - block_size + 1, block_size):
                block = gray[y:y + block_size, x:x + block_size]
                variances.append(np.var(block))

        if not variances:
            return 0.0

        mean_var = np.mean(variances)
        # Normalize to [0, 1] range
        complexity = min(mean_var / 2000.0, 1.0)
        return float(complexity)

    def _get_adaptive_quality(self, base_quality: int, complexity: float) -> int:
        """Map tile complexity to quality adjustment."""
        if complexity < 0.15:
            adjusted = base_quality - 2
        elif complexity < 0.4:
            adjusted = base_quality - 1
        elif complexity < 0.7:
            adjusted = base_quality
        else:
            adjusted = base_quality + 1

        # Clamp to valid range
        return max(1, min(8, adjusted))

    def _calculate_tile_grid(self, w: int, h: int) -> Tuple[int, int, int]:
        """
        Calculate tile grid dimensions for overlapped tiling.

        Returns:
            (n_tiles_x, n_tiles_y, stride)
        """
        if self.overlap <= 0:
            stride = self.tile_size
            n_tiles_x = math.ceil(w / self.tile_size)
            n_tiles_y = math.ceil(h / self.tile_size)
        else:
            stride = self.tile_size - self.overlap
            n_tiles_x = max(1, math.ceil((w - self.overlap) / stride))
            n_tiles_y = max(1, math.ceil((h - self.overlap) / stride))
        return n_tiles_x, n_tiles_y, stride

    def compress(
        self,
        input_path: Union[str, Path],
        output_path: Union[str, Path]
    ) -> NeuralCompressionResult:
        """
        Compress image using neural codec with overlapped tiling support.
        Writes NCI3 format with overlap and adaptive quality metadata.
        """
        input_path = Path(input_path)
        output_path = Path(output_path)

        self._log(f"\n{'='*60}")
        self._log(f"NEURAL COMPRESSION (NCI3): {input_path.name}")
        self._log(f"{'='*60}")

        # Load image
        try:
            img = Image.open(input_path).convert('RGB')
            original_size = os.path.getsize(input_path)
        except Exception as e:
            return NeuralCompressionResult(
                success=False, output_path=None, original_size=0,
                compressed_size=0, compression_ratio=0, quality_level=self.quality,
                message=f"Failed to load image: {e}"
            )

        self._log(f"Original: {img.width}x{img.height} ({original_size / (1024*1024):.2f} MB)")

        w, h = img.width, img.height
        n_tiles_x, n_tiles_y, stride = self._calculate_tile_grid(w, h)

        self._log(f"Processing in {n_tiles_x}x{n_tiles_y} tiles (overlap={self.overlap}, stride={stride})...")

        output_path.parent.mkdir(parents=True, exist_ok=True)

        try:
            with open(output_path, 'wb') as f:
                # NCI3 Header (32 bytes):
                # Magic(4) + Width(4) + Height(4) + Quality(1) + ModelID(1) +
                # TileSize(4) + Overlap(2) + TilesX(4) + TilesY(4) + Flags(1) + Reserved(3)
                magic = b'NCI3'
                model_id = self.MODEL_ID_MAP.get(self.model_name, 1)
                flags = 0
                if self.quality_mode == "adaptive":
                    flags |= 0x01  # bit 0: per-tile quality stored
                if self.use_onnx:
                    flags |= 0x02  # bit 1: ONNX model used

                header = struct.pack('<4sIIBBIHIIB3s',
                    magic, w, h,
                    self.quality, model_id,
                    self.tile_size, self.overlap,
                    n_tiles_x, n_tiles_y,
                    flags, b'\x00\x00\x00')
                f.write(header)

                total_tiles = n_tiles_x * n_tiles_y
                total_processed = 0

                for ty in range(n_tiles_y):
                    for tx in range(n_tiles_x):
                        # Calculate tile position with stride
                        x1 = tx * stride
                        y1 = ty * stride

                        # Calculate tile extent
                        x2 = min(x1 + self.tile_size, w)
                        y2 = min(y1 + self.tile_size, h)

                        target_w = x2 - x1
                        target_h = y2 - y1

                        tile = img.crop((x1, y1, x2, y2))

                        # Determine quality for this tile
                        if self.quality_mode == "adaptive":
                            complexity = self._calculate_tile_complexity(tile)
                            tile_quality = self._get_adaptive_quality(self.quality, complexity)
                            self._log(f"  Tile ({tx},{ty}): complexity={complexity:.3f}, quality={tile_quality}")
                        else:
                            tile_quality = self.quality

                        # Get model for this quality level
                        model, device = self._get_model(self.model_name, tile_quality)

                        # Pad tile to 64 multiple
                        tile_padded = self._pad_image(tile, 64)

                        # Compress tile
                        x = torch.from_numpy(np.array(tile_padded)).permute(2, 0, 1).float() / 255.0
                        x = x.unsqueeze(0).to(device)

                        with torch.no_grad():
                            out = model.compress(x)

                        # Get latent shape
                        if len(out['shape']) == 2:
                            shape_h, shape_w = out['shape'][0], out['shape'][1]
                        else:
                            shape_h, shape_w = out['shape'][2], out['shape'][3]

                        strings = out['strings']
                        str_lens = [len(s[0]) for s in strings]

                        # Write Per-Tile Block:
                        # OrigW(2) + OrigH(2) + LatentH(2) + LatentW(2) + TileQuality(1) +
                        # StrLen1(4) + StrLen2(4) + String1(var) + String2(var)
                        f.write(struct.pack('<HHHHB', target_w, target_h, shape_h, shape_w, tile_quality))
                        f.write(struct.pack('<II', str_lens[0], str_lens[1]))
                        f.write(strings[0][0])
                        f.write(strings[1][0])

                        total_processed += 1
                        if total_processed % 5 == 0:
                            self._log(f"  Processed {total_processed}/{total_tiles} tiles...")

            compressed_size = os.path.getsize(output_path)
            ratio = original_size / compressed_size if compressed_size > 0 else 0

            self._log(f"Compressed: {compressed_size / (1024*1024):.2f} MB")
            self._log(f"Ratio: {ratio:.1f}:1")
            self._log(f"{'='*60}\n")

            return NeuralCompressionResult(
                success=True,
                output_path=output_path,
                original_size=original_size,
                compressed_size=compressed_size,
                compression_ratio=ratio,
                quality_level=self.quality,
                message=f"Compressed {ratio:.1f}:1 using neural codec (NCI3, overlap={self.overlap})"
            )

        except Exception as e:
            if output_path.exists():
                output_path.unlink()
            raise e

    def _create_blend_weight(
        self, tile_h: int, tile_w: int,
        overlap: int,
        is_left: bool, is_right: bool,
        is_top: bool, is_bottom: bool
    ) -> np.ndarray:
        """
        Create a blending weight mask for a tile.

        Applies linear gradient ramps on overlap edges, but skips ramps
        on image borders (where there's no neighbor to blend with).
        """
        mask = np.ones((tile_h, tile_w), dtype=np.float32)

        if overlap <= 0:
            return mask

        # Left overlap ramp (skip if this tile is at the left border)
        if not is_left:
            ramp_len = min(overlap, tile_w)
            ramp = np.linspace(0.0, 1.0, ramp_len, dtype=np.float32)
            mask[:, :ramp_len] *= ramp[np.newaxis, :]

        # Right overlap ramp (skip if this tile is at the right border)
        if not is_right:
            ramp_len = min(overlap, tile_w)
            ramp = np.linspace(1.0, 0.0, ramp_len, dtype=np.float32)
            mask[:, -ramp_len:] *= ramp[np.newaxis, :]

        # Top overlap ramp (skip if this tile is at the top border)
        if not is_top:
            ramp_len = min(overlap, tile_h)
            ramp = np.linspace(0.0, 1.0, ramp_len, dtype=np.float32)
            mask[:ramp_len, :] *= ramp[:, np.newaxis]

        # Bottom overlap ramp (skip if this tile is at the bottom border)
        if not is_bottom:
            ramp_len = min(overlap, tile_h)
            ramp = np.linspace(1.0, 0.0, ramp_len, dtype=np.float32)
            mask[-ramp_len:, :] *= ramp[:, np.newaxis]

        return mask

    def decompress(
        self,
        compressed_path: Union[str, Path],
        output_path: Union[str, Path]
    ) -> NeuralCompressionResult:
        """
        Decompress NCI2 or NCI3 file with automatic format detection.
        """
        compressed_path = Path(compressed_path)
        output_path = Path(output_path)

        self._log(f"\n{'='*60}")
        self._log(f"NEURAL DECOMPRESSION: {compressed_path.name}")
        self._log(f"{'='*60}")

        compressed_size = os.path.getsize(compressed_path)

        with open(compressed_path, 'rb') as f:
            # Peek at magic to determine format
            magic = f.read(4)
            f.seek(0)

            if magic == b'NCI3':
                return self._decompress_nci3(f, output_path, compressed_size)
            elif magic == b'NCI2':
                return self._decompress_nci2(f, output_path, compressed_size)
            else:
                return NeuralCompressionResult(
                    success=False, output_path=None, original_size=0,
                    compressed_size=compressed_size, compression_ratio=0,
                    quality_level=0, message=f"Invalid file format: {magic}"
                )

    def _decompress_nci2(self, f, output_path: Path, compressed_size: int) -> NeuralCompressionResult:
        """Decompress legacy NCI2 format (no overlap, no adaptive quality)."""
        header_fmt = '<4sIIBBIII'
        header_len = struct.calcsize(header_fmt)
        header_data = f.read(header_len)

        magic, total_w, total_h, quality, model_id, tile_size, n_tiles_x, n_tiles_y = struct.unpack(header_fmt, header_data)

        self._log(f"Format: NCI2 (legacy)")
        self._log(f"Image: {total_w}x{total_h}, Tiles: {n_tiles_x}x{n_tiles_y}")

        model_name = self.MODEL_NAME_MAP.get(model_id, "mbt2018_mean")
        model, device = self._get_model(model_name, quality)

        canvas = Image.new('RGB', (total_w, total_h))
        total_tiles = n_tiles_x * n_tiles_y
        processed = 0

        for ty in range(n_tiles_y):
            for tx in range(n_tiles_x):
                tile_head_fmt = '<HHHH'
                tile_head_len = struct.calcsize(tile_head_fmt)
                tile_head = f.read(tile_head_len)
                target_w, target_h, shape_h, shape_w = struct.unpack(tile_head_fmt, tile_head)

                len_data = f.read(8)
                len1, len2 = struct.unpack('<II', len_data)

                str1 = f.read(len1)
                str2 = f.read(len2)
                strings = [[str1], [str2]]

                with torch.no_grad():
                    rec = model.decompress(strings, (shape_h, shape_w))

                rec_tile = (rec['x_hat'].squeeze().cpu().permute(1, 2, 0).numpy() * 255)
                rec_tile = rec_tile.clip(0, 255).astype(np.uint8)

                tile_img = Image.fromarray(rec_tile[:target_h, :target_w])

                x1 = tx * tile_size
                y1 = ty * tile_size
                canvas.paste(tile_img, (x1, y1))

                processed += 1
                if processed % 5 == 0:
                    self._log(f"  Decompressed {processed}/{total_tiles} tiles...")

        return self._save_output(canvas, output_path, total_w, total_h, compressed_size, quality)

    def _decompress_nci3(self, f, output_path: Path, compressed_size: int) -> NeuralCompressionResult:
        """Decompress NCI3 format with overlap blending and adaptive quality."""
        # NCI3 Header (32 bytes)
        header_fmt = '<4sIIBBIHIIB3s'
        header_len = struct.calcsize(header_fmt)
        header_data = f.read(header_len)

        (magic, total_w, total_h, quality, model_id,
         tile_size, overlap, n_tiles_x, n_tiles_y,
         flags, _reserved) = struct.unpack(header_fmt, header_data)

        has_per_tile_quality = bool(flags & 0x01)
        uses_onnx = bool(flags & 0x02)

        model_name = self.MODEL_NAME_MAP.get(model_id, "mbt2018_mean")

        self._log(f"Format: NCI3 (overlap={overlap}, adaptive={'yes' if has_per_tile_quality else 'no'})")
        self._log(f"Image: {total_w}x{total_h}, Tiles: {n_tiles_x}x{n_tiles_y}")

        # Calculate stride
        if overlap > 0:
            stride = tile_size - overlap
        else:
            stride = tile_size

        # Try ONNX inference if flagged and available
        onnx_engine = None
        if uses_onnx and self.use_onnx:
            onnx_engine = self._get_onnx_engine()

        # First pass: read all tile data
        tile_data_list = []
        for ty in range(n_tiles_y):
            for tx in range(n_tiles_x):
                # Per-Tile Block:
                # OrigW(2) + OrigH(2) + LatentH(2) + LatentW(2) + TileQuality(1) +
                # StrLen1(4) + StrLen2(4) + String1(var) + String2(var)
                tile_head_fmt = '<HHHHB'
                tile_head_len = struct.calcsize(tile_head_fmt)
                tile_head = f.read(tile_head_len)
                target_w, target_h, shape_h, shape_w, tile_quality = struct.unpack(tile_head_fmt, tile_head)

                len_data = f.read(8)
                len1, len2 = struct.unpack('<II', len_data)

                str1 = f.read(len1)
                str2 = f.read(len2)

                tile_data_list.append({
                    'tx': tx, 'ty': ty,
                    'target_w': target_w, 'target_h': target_h,
                    'shape_h': shape_h, 'shape_w': shape_w,
                    'tile_quality': tile_quality,
                    'strings': [[str1], [str2]],
                })

        # Pre-load all needed model quality levels
        needed_qualities = set(td['tile_quality'] for td in tile_data_list)
        for q in needed_qualities:
            self._get_model(model_name, q)

        # Float32 canvas + weight canvas for blending
        canvas = np.zeros((total_h, total_w, 3), dtype=np.float32)
        weight = np.zeros((total_h, total_w), dtype=np.float32)

        total_tiles = len(tile_data_list)

        for idx, td in enumerate(tile_data_list):
            tx, ty = td['tx'], td['ty']
            tile_quality = td['tile_quality']

            # Decompress tile
            if onnx_engine is not None:
                try:
                    rec_tile = onnx_engine.decompress(
                        td['strings'], (td['shape_h'], td['shape_w'])
                    )
                except Exception:
                    # Fallback to PyTorch
                    model, device = self._get_model(model_name, tile_quality)
                    with torch.no_grad():
                        rec = model.decompress(td['strings'], (td['shape_h'], td['shape_w']))
                    rec_tile = (rec['x_hat'].squeeze().cpu().permute(1, 2, 0).numpy() * 255)
                    rec_tile = rec_tile.clip(0, 255).astype(np.float32)
            else:
                model, device = self._get_model(model_name, tile_quality)
                with torch.no_grad():
                    rec = model.decompress(td['strings'], (td['shape_h'], td['shape_w']))
                rec_tile = (rec['x_hat'].squeeze().cpu().permute(1, 2, 0).numpy() * 255)
                rec_tile = rec_tile.clip(0, 255).astype(np.float32)

            # Crop padding
            rec_tile = rec_tile[:td['target_h'], :td['target_w']]

            # Calculate tile position
            x1 = tx * stride
            y1 = ty * stride
            x2 = x1 + td['target_w']
            y2 = y1 + td['target_h']

            # Create blending weight mask
            is_left = (tx == 0)
            is_right = (tx == n_tiles_x - 1)
            is_top = (ty == 0)
            is_bottom = (ty == n_tiles_y - 1)

            blend_mask = self._create_blend_weight(
                td['target_h'], td['target_w'],
                overlap, is_left, is_right, is_top, is_bottom
            )

            # Accumulate with blending weights
            canvas[y1:y2, x1:x2] += rec_tile * blend_mask[:, :, np.newaxis]
            weight[y1:y2, x1:x2] += blend_mask

            processed = idx + 1
            if processed % 5 == 0:
                self._log(f"  Decompressed {processed}/{total_tiles} tiles...")

        # Normalize by weights
        weight = np.maximum(weight, 1e-8)  # Avoid division by zero
        result_img = (canvas / weight[:, :, np.newaxis]).clip(0, 255).astype(np.uint8)

        result_pil = Image.fromarray(result_img)

        return self._save_output(result_pil, output_path, total_w, total_h, compressed_size, quality)

    def _save_output(
        self, img: Image.Image, output_path: Path,
        total_w: int, total_h: int,
        compressed_size: int, quality: int
    ) -> NeuralCompressionResult:
        """Save decompressed image and return result."""
        output_path.parent.mkdir(parents=True, exist_ok=True)
        if output_path.suffix.lower() in ['.jpg', '.jpeg']:
            img.save(output_path, 'JPEG', quality=95)
        else:
            img.save(output_path)

        output_size = os.path.getsize(output_path)

        self._log(f"Decompressed: {total_w}x{total_h} ({output_size / (1024*1024):.2f} MB)")
        self._log(f"{'='*60}\n")

        return NeuralCompressionResult(
            success=True,
            output_path=output_path,
            original_size=output_size,
            compressed_size=compressed_size,
            compression_ratio=output_size / compressed_size if compressed_size > 0 else 0,
            quality_level=quality,
            message="Successfully decompressed"
        )
